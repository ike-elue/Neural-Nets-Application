{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pen Recognition CNN Keras Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBxP1yqf_8fd",
        "colab_type": "text"
      },
      "source": [
        "Learning Convolutional Neural Networks (CNNs)\n",
        "- https://cdn-images-1.medium.com/max/1600/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg\n",
        "- https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/2934e9a15d0619d04ae4a4d4e2951e2ff4f45d93/21-FigureD.2-1.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbCj8C51foFy",
        "colab_type": "text"
      },
      "source": [
        "Quick Side Note:\n",
        "- ReLUs https://thumbs.gfycat.com/GoodShinyGhostshrimp-size_restricted.gif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzgBfLiBAuBf",
        "colab_type": "text"
      },
      "source": [
        "How does this differ from the neural networks we've looked at?\n",
        "- Flatten\n",
        "  - https://cdn-images-1.medium.com/max/1600/1*Lzx2pNLpHjGTKcofsaSH1g.png\n",
        "- Convultions \n",
        "  - https://media3.giphy.com/media/i4NjAwytgIRDW/giphy.gif\n",
        "  - we use \"same\" padding instead of \"valid\" padding because we want to keep shape\n",
        "    - same padding puts zeros on outside\n",
        "    - https://qph.fs.quoracdn.net/main-qimg-9e3419cfcd8535fb289bb1b710920d2f\n",
        "- Pooling\n",
        "  - optional\n",
        "    - in our model we won't use it because it breaks the model/makes it not work as well\n",
        "  - average pooling\n",
        "    - general parts (smooth)\n",
        "  - max pooling\n",
        "    - sharpest parts (edges)\n",
        "    - https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9AhVQ7QBGYe",
        "colab_type": "text"
      },
      "source": [
        "What do we have to do the code below to translate it into a functional CNN?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4gOLn4xBT-p",
        "colab_type": "code",
        "outputId": "998f07eb-c35b-4dad-a0a0-7c5f5109a54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn import preprocessing as pr \n",
        "\n",
        "dataset = pd.read_csv(\"https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/datasets/digits.csv\")\n",
        "datasetArray = np.array(dataset)\n",
        "xfData = pr.normalize(datasetArray.T[0:-1].T)\n",
        "yfData = datasetArray.T[-1]\n",
        "yfData = yfData.T\n",
        "yData = np.zeros((yfData.shape[0], 10))\n",
        "for i in range(yfData.shape[0]):\n",
        "  yData[i][yfData[i]] = 1\n",
        "\n",
        "amountOfData = 9000\n",
        "trainingData = xfData[0:amountOfData]\n",
        "testingData = xfData[amountOfData:]\n",
        "\n",
        "trainingLabels = yData[0:amountOfData]   \n",
        "testingLabels = yData[amountOfData:]\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(trainingData, trainingLabels, epochs=6)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(testingData, testingLabels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/6\n",
            "9000/9000 [==============================] - 1s 115us/sample - loss: 0.0727 - acc: 0.4877\n",
            "Epoch 2/6\n",
            "9000/9000 [==============================] - 1s 98us/sample - loss: 0.0317 - acc: 0.8326\n",
            "Epoch 3/6\n",
            "9000/9000 [==============================] - 1s 97us/sample - loss: 0.0235 - acc: 0.8508\n",
            "Epoch 4/6\n",
            "9000/9000 [==============================] - 1s 94us/sample - loss: 0.0207 - acc: 0.8704\n",
            "Epoch 5/6\n",
            "9000/9000 [==============================] - 1s 106us/sample - loss: 0.0189 - acc: 0.8816\n",
            "Epoch 6/6\n",
            "9000/9000 [==============================] - 1s 107us/sample - loss: 0.0175 - acc: 0.8918\n",
            "1991/1991 [==============================] - 0s 79us/sample - loss: 0.0154 - acc: 0.9081\n",
            "Test accuracy: 0.90808636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsWKw0rEBoNE",
        "colab_type": "text"
      },
      "source": [
        "We have to: \n",
        "- Reshape\n",
        "- Continue Normalization (It's still important)\n",
        "- Remove One Hot Encoding\n",
        "- Bring in idea of batches\n",
        "- Look at API\n",
        "  - https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l04c01_image_classification_with_cnns.ipynb#scrollTo=Gl91RPhdCaXI\n",
        "  - https://keras.io/models/model/\n",
        "  - https://keras.io/layers/convolutional/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfS407PSPdms",
        "colab_type": "text"
      },
      "source": [
        "2D Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-XQFiNQ5-xa",
        "colab_type": "code",
        "outputId": "8e1eb76f-5e2f-424f-96eb-1a781520bb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn import preprocessing as pr \n",
        "\n",
        "dataset = pd.read_csv(\"https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/datasets/digits.csv\")\n",
        "datasetArray = np.array(dataset)\n",
        "xfData = pr.normalize(datasetArray.T[0:-1].T)\n",
        "yfData = datasetArray.T[-1].T\n",
        "\n",
        "amountOfData = 9000\n",
        "\n",
        "trainingData = tf.reshape(xfData[0:amountOfData], [amountOfData, 4, 4, 1])\n",
        "testingData = tf.reshape(xfData[amountOfData:], [xfData.shape[0] - amountOfData, 4, 4, 1])\n",
        "\n",
        "trainingLabels = tf.reshape(yfData[0:amountOfData], [amountOfData, 1])   \n",
        "testingLabels = tf.reshape(yfData[amountOfData:], [xfData.shape[0] - amountOfData, 1])\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu, input_shape=(4,4,1)),\n",
        "    #keras.layers.MaxPooling2D((2, 2), strides=2), Not Needed\n",
        "    keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    #keras.layers.MaxPooling2D((2, 2), strides=2), This crashes it\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',#loss='mean_squared_error', looking for categorical so this is better\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch = 100\n",
        "\n",
        "model.fit(trainingData, trainingLabels, epochs=10, steps_per_epoch=math.ceil(amountOfData/batch))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(testingData, testingLabels, steps=batch)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 2s 27ms/step - loss: 1.0093 - acc: 0.6993\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1456 - acc: 0.9638\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0554 - acc: 0.9883\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0318 - acc: 0.9945\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0214 - acc: 0.9969\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0159 - acc: 0.9978\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0127 - acc: 0.9984\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0106 - acc: 0.9988\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0092 - acc: 0.9991\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0083 - acc: 0.9993\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0132 - acc: 0.9960\n",
            "Test accuracy: 0.99598193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqF_p19_Pkak",
        "colab_type": "text"
      },
      "source": [
        "1D Convolutions + Dropout\n",
        "- There's no difference in this versus 2D, but this is interesting cuz of dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD4fQ_nQMTH_",
        "colab_type": "code",
        "outputId": "9a42112b-6019-4df8-b3f7-a226419254ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn import preprocessing as pr \n",
        "\n",
        "dataset = pd.read_csv(\"https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/datasets/digits.csv\")\n",
        "datasetArray = np.array(dataset)\n",
        "xfData = pr.normalize(datasetArray.T[0:-1].T)\n",
        "yfData = datasetArray.T[-1].T\n",
        "\n",
        "amountOfData = 9000\n",
        "\n",
        "trainingData = tf.reshape(xfData[0:amountOfData], [amountOfData, 16, 1])\n",
        "testingData = tf.reshape(xfData[amountOfData:], [xfData.shape[0] - amountOfData, 16, 1])\n",
        "\n",
        "trainingLabels = tf.reshape(yfData[0:amountOfData], [amountOfData, 1])   \n",
        "testingLabels = tf.reshape(yfData[amountOfData:], [xfData.shape[0] - amountOfData, 1])\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv1D(32, 3, activation=tf.nn.relu, input_shape=(16,1)),\n",
        "    keras.layers.Dropout(.25),\n",
        "    keras.layers.Conv1D(64, 3, padding='same', activation=tf.nn.relu),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "    keras.layers.Dropout(.25),\n",
        "    keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch = 100\n",
        "\n",
        "model.fit(trainingData, trainingLabels, epochs=10, steps_per_epoch=math.ceil(amountOfData/batch))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(testingData, testingLabels, steps=batch)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 1.2503 - acc: 0.6271\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.3342 - acc: 0.9005\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1808 - acc: 0.9466\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1250 - acc: 0.9635\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0982 - acc: 0.9717\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0807 - acc: 0.9770\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0689 - acc: 0.9805\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0608 - acc: 0.9827\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0535 - acc: 0.9848\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0471 - acc: 0.9866\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0135 - acc: 0.9960\n",
            "Test accuracy: 0.99598193\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}